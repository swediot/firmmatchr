% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_api.R
\name{azure_chat_request}
\alias{azure_chat_request}
\title{Internal Azure Chat Completion Wrapper (Custom Endpoint)}
\usage{
azure_chat_request(
  system_msg,
  user_msg,
  endpoint,
  api_key,
  deployment,
  api_version = "2024-04-14"
)
}
\arguments{
\item{system_msg}{String. The instructions for the LLM.}

\item{user_msg}{String. The specific case to evaluate.}

\item{endpoint}{String. Base URL.}

\item{api_key}{String. API Key.}

\item{deployment}{String. Model/Deployment name.}

\item{api_version}{String. API version (unused in this custom path but kept for compatibility).}
}
\value{
A character string (the JSON response) or NULL on failure.
}
\description{
Sends a request to a custom Azure-like endpoint (e.g. /openai/v1/responses).
}
\keyword{internal}
